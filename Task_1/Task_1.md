## 一.数学基础

### 1.矩阵微积分

​	定义一个函数$f$，以$m * n$的矩阵$A$为输入，输出为实数。那么$f$的梯度为实数关于矩阵的偏导数矩阵，也就是函数值对$A_{ij}$求导。

### 2.概率论——最大似然估计

​	通过一定的实验事实，推断出最有可能的概率参数情况，就是最大似然估计。

​	离散化样本中，似然函数与概率等价。



## 二.模型的评价和选择

### 1.分类器模型评估指标

#### （一）混淆矩阵（$Confusion Matrix$)

对于二分类问题来说，分类器将模型拟合之后最终会出现四种结果：

(1)真正例（true positive）简称$TP$；

(2)假正例（false positive）简称$FP$；

(3)假反例（false negative）简称$FN$；

(4)真反例（true negative）简称$TN$；

对于这四种将这四种情况统计起来形成的表格所对应的矩阵，称为混淆矩阵。

#### （二）准确率（$Accuracy$)

假设样本的总数为N，那么准确率的定义为：$\frac{TP+TN}{N }\times100$%

即预测准确的总数与样本总数的比值。

#### （三）精确率（$Precision$）、召回率（$Recall$）

精确率（$precision$，简称P）是指预测结果为true的样本中，$TP$所占的比例，即 $P=\frac{TP}{TP+FP}$

召回率（$recall$，简称R）是指样本中真实结果为positive当中，$TP$所占的比例，即$R=\frac{TP}{TP+FN}$

#### （四）F1$值

$F1$值是指$precision$和$recall$的调和平均，即：
$F1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2PR}{P+R}$

#### （五）$ROC$曲线、$TPR、FPR$

$TPR$（true position rate，真正例率）是指预测正确为positive的样本占全体positive的比例，即：

$TPR=\frac{TP}{TP+FN}\times100$%

$FPR$（false position rate，假正例率）是指预测错误为positive的样本占全体negative的比例，即：

$FPR=\frac{FP}{TN+FP}\times100$%

$ROC$曲线是指以$FPR$为横轴，以$TPR$为纵轴的曲线，其积分的值称为$AUC$。获得方法：在坐标(0,0)处标记一个点，然后依次将分类阈值设定为每个样例的预测值（提高阈值，比如0.5就是大于0.5时将其预测为positive），依次将每个样例划分为正例。

#### （六）$ROC$曲线和$PR$曲线的选用

$ROC$曲线对于正例和负例同样的敏感，而$PR$曲线对于正例比较敏感，当我们对于正例的需求更加严格时，就应当选用$PR$曲线。

$eg.$我现在拥有500个样本，其中正例7个，反例493个。在这种情况下，分类器仍然没有预测准确任何一个正例，但是对于负例的预测的准确率较高，此时，$ROC$曲线显示模型的表现较好，而$PR$曲线显示模型的表现较差。因此，当我们对于正例要求更加严格时，应当选用$PR$曲线来作为评估标准。

同时，$ROC$曲线对于正反例不敏感的事实也说明，在更改样本时，他的稳定性比较高，（当我们对模型的稳定性有所需求时，则应当选用$ROC$曲线。）

### 2.回归器模型评估指标

#### （一）均方误差（Mean Squared Error,$MSE$)

$MSE = \frac{1}{n}\sum((y_i-\hat{y}_i)^2)$（与损失函数类似）

#### （二）均方根误差和平均绝对误差($RMSE$&$MAE$)

$RMSE = \sqrt{MSE}$

$MAE = \frac{\sum|y_i-\hat{y}_i|}{n}$

#### （三）决定系数$R^2$

$TSS$ (Total Sum of Squares)

$RSS$ (Residual Sum of Squares)

$R^2 = \frac{TSS-RSS}{TSS}$

## 三.多分类问题

​	一般来说，解决多分类问题的基本思路是“拆解法”，有常见的三种拆分策略：$OvO,OvR,MvM$。

$OvO$：将$N$个类别两两配对，产生多个分类任务，得到多个分类结果，把被预测得最多的类别作为最终分类结果。

$OvR$：将一个类作为正例，其他类作为反例来进行训练。若竟有一个分类器预测为正类，则对应的类别标记作为最终分类结果；若有多个分类器预测为正类，则考虑每一个分类器的置信度，取高者。

$MvM$：将若干类作为正类，若干其他类作为反类。正反类必须有特殊的设计（$ECOC$）：

1.每次划分一部分类别为正类，一部分划分为反类，从而形成一个二分类训练集；

2.分别对样本进行预测，预测标记组成一个编码，将这个编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。

## 四.类别不平衡问题

​	基本策略：“再缩放“。有三种方法：”欠采样“、”过采样“、”阈值移动“

​	”欠采样”：去除一些反例使正反例数目接近；

​	“过采样”：通过对训练集里的正例进行插值来产生额外的正例。

​	“阈值移动”：

如果正反例数目相同，我们一般采用$\frac{y}{1-y}>1$即$y>0.5$来预测正类，但是若类别不平衡时，我们需要对阈值进行调整：

$\frac{y'}{1-y'} = \frac{y}{1-y} * \frac{m^-}{m^+}$来计算阈值，其中$m^+$表示正类数目。