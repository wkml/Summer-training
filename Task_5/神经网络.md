## 神经网络

### 1.感知机

​	感知机就是一个input神经元加上一个output神经元，只有一层网络结构，一个线性回归和逻辑回归都类似感知机。

### 2.损失函数

​	神经网络的损失函数有两种：二次代价函数和交叉熵函数，代码里我主要还是采用二次代价函数。

### 3.$BPNN$

​	$BPNN$主要是采用$BP$算法的前馈网络，一次训练一组数据，根据预测结果与实际结果的差值，不断向前反馈误差给前面的神经元，运用与梯度下降类似的更新手段来更新参数：

​	1.将损失分别对权重和偏置求解导数，（梯度），根据梯度的逆方向来更新权重和偏置，多次重复，就可以解得最优解（局部、全局）

​	**避免过拟合的方法**：添加L2范式，对权重的更新进行适当的干扰。

​	**避免陷入局部最优解的方法**：使用随机梯度下降，开始时的权重随机设置，并且训练集suffer。

​	为减少各个节点误差：（误差为正表示输出应当减小，反之增加，以下说明以误差为正值为前提）
​    1.调整权重：减小该节点所有正输入对应权重，增加所有负输入对应权重
​    2.减小偏置
​    3.调整上一层的输出：减少正权重对应输出，增加负权重对应输出（反向传递）
此外：不同误差表示调整该节点的性价比，误差很小意味着该节点输出很接近期望，即没必要调整，反之则意味着调整的性价比很高
​     相应计算出的对应梯度绝对值大小表示调整的性价比

### 4.小批量学习

​	将数据分为多个小数据，每次区分前进行suffer，多周期传入给神经网络进行学习。

