## 支持向量机

1.支持向量机做的事情

​	对二维平面上的一组数据具有两种标签，支持向量机就是要找出一个超平面，使得这个平面既可以区分两种标签出来，又可以平移的距离最大（泛化误差）。

​	二维平面上任意一条线可以被表示为：$x_1=ax_2+b$ 稍微变换可以得到 $0=w^Tx+b$ .

​	二维空间中，直线就是超平面，于是，对于支持向量机所要寻找的超平面，我们可以找到决策边界的两个超平面

 $w^Tx+b=1$ 和$w^Tx+b=-1$ .

这两条线上会过决策边界的两个点，于是经过简单的高中数学推导，可以得到两条线之间的距离公式：

$d = \frac{2}{||w||}$  为了让他们之间的距离最大，以让支持向量机可以找到的直线泛化误差最大，就是要求解$||w||$的最小值，于是就得出了支持向量机的损失函数：

2.支持向量机的损失函数

$f(w) = \frac{||w||}{2}$  ，这个$w$作为一个向量，里面有一堆数字，目前暂时不知道有什么具体意义~在二维平面上，主要决定了截距。 附加条件为：点是边界上的点，所以：$y_i({w}{x_i}+b)>=1$  高数书上的经典条件极值问题，采用拉格朗日数乘法。

​	总之，求解到最后会带有拉格朗日乘数，无法得到确切的值，于是，引入了对偶函数，来解决这个问题。求拉格朗日函数的最小值解，就是求对偶函数的最大值解。（前提是强对偶，满足KKT）

​	运用SMO算法，迭代求解，最终可以得到$w$的值。(有点懒直接手推了)

<img src="https://github.com/wkml5994/Summer-training/raw/wkml5994-patch-1/微信图片_20210721140056.jpg" alt="SMO" style="zoom:10%;" />

