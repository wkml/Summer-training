# 降维算法

### $SVD$矩阵分解

​	对一个对称矩阵来说，其必定存在一个相似矩阵，且该矩阵为对角阵，公式表述为：
$$
PAP^T=\Lambda
$$
其中A为对称阵，$\Lambda$为对角阵。

那么，A可以分解为：
$$
A=U\Lambda U^{-1}
$$
其中$U=P^{-1}$

推广到非对称阵中，有：
$$
A=U\Xi V^T
$$
其中$\Xi$为奇异值矩阵（对角阵） $U$、$V$为两个正交阵。

（可以直接调用np.linalg.svd​(mat)来求解某矩阵的SVD分解）

### $PCA$降维

​	$PCA$，主成分分析法，应用最广泛的数据降维方法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是**从原始的空间中顺序地找一组相互正交的坐标轴**，新的坐标轴的选择与数据本身是密切相关的。其中，**第一个新坐标轴选择是原始数据中方差最大的方向**，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。